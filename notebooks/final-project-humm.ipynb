{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48c377e0",
   "metadata": {},
   "source": [
    "# Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41cfd1f",
   "metadata": {},
   "source": [
    "## Step 1: Migration Data Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "672a5822",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pygbif'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mgetpass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m getpass\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m glob\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpygbif\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moccurrences\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mocc\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpygbif\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mspecies\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspecies\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrequests\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pygbif'"
     ]
    }
   ],
   "source": [
    "# Import needed Python libraries\n",
    "import time\n",
    "import zipfile\n",
    "from getpass import getpass\n",
    "from glob import glob\n",
    "\n",
    "import pygbif.occurrences as occ\n",
    "import pygbif.species as species\n",
    "import requests\n",
    "\n",
    "# Python Standard Library Packages\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Other Packages\n",
    "import earthpy # Manage local data\n",
    "import pandas as pd # Work with tabular data\n",
    "import geopandas as gpd # Work with geospatial vector data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "\n",
    "# Get month names\n",
    "import calendar\n",
    "\n",
    "# Libraries for Dynamic mapping\n",
    "import cartopy.crs as ccrs\n",
    "import hvplot.pandas\n",
    "import panel as pn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53e3c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "data_dir = os.path.join(\n",
    "\n",
    "    ### Home directory\n",
    "    pathlib.Path.home(),\n",
    "\n",
    "    ### Make folders\n",
    "    'earth-analytics',\n",
    "    'data',\n",
    "\n",
    "    ### Project directory for this assignment\n",
    "    'final-hummbird', \n",
    ")\n",
    "\n",
    "## Make the path\n",
    "os.makedirs(data_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a78223",
   "metadata": {},
   "source": [
    "## STEP 2: Register and log in to GBIF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67f8705",
   "metadata": {},
   "outputs": [],
   "source": [
    "####--------------------------####\n",
    "#### DO NOT MODIFY THIS CODE! ####\n",
    "####--------------------------####\n",
    "# This code ASKS for your credentials \n",
    "# and saves it for the rest of the session.\n",
    "# NEVER put your credentials into your code!!!!\n",
    "\n",
    "# GBIF needs a username, password, and email \n",
    "# All 3 need to match the account\n",
    "reset = True\n",
    "\n",
    "# Request and store username\n",
    "if (not ('GBIF_USER'  in os.environ)) or reset:\n",
    "    os.environ['GBIF_USER'] = input('GBIF username:')\n",
    "\n",
    "# Securely request and store password\n",
    "if (not ('GBIF_PWD'  in os.environ)) or reset:\n",
    "    os.environ['GBIF_PWD'] = getpass('GBIF password:')\n",
    "    \n",
    "# Request and store account email address\n",
    "if (not ('GBIF_EMAIL'  in os.environ)) or reset:\n",
    "    os.environ['GBIF_EMAIL'] = input('GBIF email:')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b8eb2d",
   "metadata": {},
   "source": [
    "## STEP 3: Get the taxon key from GBIF\n",
    "\n",
    "One of the tricky parts about getting occurrence data from GBIF is that\n",
    "species often have multiple names in different contexts. Luckily, GBIF\n",
    "also provides a Name Backbone service that will translate scientific and\n",
    "colloquial names into unique identifiers. GBIF calls these identifiers\n",
    "**taxon keys**. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284ce74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the 2 distinct species key from GBIF \n",
    "backbone_ruby = species.name_backbone(name='Archilochus colubris')\n",
    "backbone_broad = species.name_backbone(name='Selasphorus platycercus')\n",
    "\n",
    "species_key_ruby = backbone_ruby['usageKey']\n",
    "species_key_broad = backbone_broad['usageKey']\n",
    "\n",
    "# Retrieve usage key and confirm existence\n",
    "print(\"The usage key for Ruby is: \" , species_key_ruby)\n",
    "print(\"The usage key for Broad-Tail is: \", species_key_broad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1186ec0c",
   "metadata": {},
   "source": [
    "## STEP 4: Download data from GBIF\n",
    "\n",
    "Downloading GBIF data is a multi-step process. \n",
    "\n",
    "For this final project, we will be using two different species of hummingbird, so will need to run this information twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d609536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "ruby_dir = os.path.join(\n",
    "\n",
    "    ### Home directory\n",
    "    pathlib.Path.home(),\n",
    "\n",
    "    ### Make folders\n",
    "    'earth-analytics',\n",
    "    'data',\n",
    "\n",
    "    ### Project directory for this assignment\n",
    "    'final-hummbird', \n",
    "    'ruby'\n",
    ")\n",
    "\n",
    "## Make the path\n",
    "os.makedirs(ruby_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea1fae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only download once\n",
    "gbif_pattern_ruby = os.path.join(ruby_dir, '*.csv')\n",
    "\n",
    "if not glob(gbif_pattern_ruby):\n",
    "    \n",
    "    # Only submit one request\n",
    "    if not 'GBIF_DOWNLOAD_KEY' in os.environ:\n",
    "        # Submit query to GBIF\n",
    "        gbif_query = occ.download([\n",
    "            f\"taxonKey = {species_key_ruby}\",\n",
    "            \"hasCoordinate = True\",\n",
    "            f\"year = 2024\",\n",
    "        ])\n",
    "        # Take first result\n",
    "        os.environ['GBIF_DOWNLOAD_KEY'] = gbif_query[0]\n",
    "\n",
    "    # Wait for the download to build\n",
    "    dld_key = os.environ['GBIF_DOWNLOAD_KEY']\n",
    "\n",
    "    # use the occurrence command module in pygbif to get the metadata\n",
    "    wait = occ.download_meta(dld_key)['status']\n",
    "\n",
    "    # check if the status of the download = \"SUCCEEDED\"\n",
    "    # wait and loop through until it finishes\n",
    "    while not wait=='SUCCEEDED':\n",
    "        wait = occ.download_meta(dld_key)['status']\n",
    "        time.sleep(5)\n",
    "\n",
    "    # Download GBIF data\n",
    "    dld_info = occ.download_get(\n",
    "        os.environ['GBIF_DOWNLOAD_KEY'], \n",
    "        path=ruby_dir)\n",
    "    dld_path = dld_info['path']\n",
    "\n",
    "    # Unzip GBIF data\n",
    "    with zipfile.ZipFile(dld_path) as dld_zip:\n",
    "        dld_zip.extractall(path=ruby_dir)\n",
    "        \n",
    "    # Clean up the .zip file\n",
    "    os.remove(dld_path)\n",
    "\n",
    "    \n",
    "\n",
    "else: print(\"Done!\") # If file already exists in folder    \n",
    "\n",
    "# Find the extracted .csv file path (first result)\n",
    "gbif_path_ruby = glob(gbif_pattern_ruby)[0]\n",
    "\n",
    "#Rename the file to a descriptive name\n",
    "csv_filename = os.path.basename(gbif_path_ruby)\n",
    "\n",
    "ruby_gbif = \"ruby-gbif.csv\"\n",
    "new_path1 = os.path.join(ruby_dir, ruby_gbif)\n",
    "\n",
    "os.rename(gbif_path_ruby, new_path1)\n",
    "\n",
    "print(f\"Renamed {csv_filename} → {ruby_gbif}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2594dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory\n",
    "broad_dir = os.path.join(\n",
    "\n",
    "    ### Home directory\n",
    "    pathlib.Path.home(),\n",
    "\n",
    "    ### Make folders\n",
    "    'earth-analytics',\n",
    "    'data',\n",
    "\n",
    "    ### Project directory for this assignment\n",
    "    'final-hummbird', \n",
    "    'broad'\n",
    ")\n",
    "\n",
    "## Make the path\n",
    "os.makedirs(broad_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d105e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only download once\n",
    "gbif_pattern_broad = os.path.join(broad_dir, '*.csv')\n",
    "\n",
    "if not glob(gbif_pattern_broad):\n",
    "    \n",
    "    # Only submit one request\n",
    "    if not 'GBIF_DOWNLOAD_KEY_1' in os.environ:\n",
    "        # Submit query to GBIF\n",
    "        gbif_query = occ.download([\n",
    "            f\"taxonKey = {species_key_broad}\",\n",
    "            \"hasCoordinate = True\",\n",
    "            f\"year = 2024\",\n",
    "        ])\n",
    "        # Take first result\n",
    "        os.environ['GBIF_DOWNLOAD_KEY_1'] = gbif_query[0]\n",
    "\n",
    "    # Wait for the download to build\n",
    "    dld_key = os.environ['GBIF_DOWNLOAD_KEY_1']\n",
    "\n",
    "    # use the occurrence command module in pygbif to get the metadata\n",
    "    wait = occ.download_meta(dld_key)['status']\n",
    "\n",
    "    # check if the status of the download = \"SUCCEEDED\"\n",
    "    # wait and loop through until it finishes\n",
    "    while not wait=='SUCCEEDED':\n",
    "        wait = occ.download_meta(dld_key)['status']\n",
    "        time.sleep(5)\n",
    "\n",
    "    # Download GBIF data\n",
    "    dld_info = occ.download_get(\n",
    "        os.environ['GBIF_DOWNLOAD_KEY_1'], \n",
    "        path=data_dir)\n",
    "    dld_path = dld_info['path']\n",
    "\n",
    "    # Unzip GBIF data\n",
    "    with zipfile.ZipFile(dld_path) as dld_zip:\n",
    "        dld_zip.extractall(path=broad_dir)\n",
    "        \n",
    "    # Clean up the .zip file\n",
    "    os.remove(dld_path)\n",
    "\n",
    "    \n",
    "\n",
    "else: print(\"Done!\") # If file already exists in folder    \n",
    "\n",
    "# Find the extracted .csv file path (first result)\n",
    "gbif_path_broad = glob(gbif_pattern_broad)[0]\n",
    "\n",
    "#Rename the file to a descriptive name\n",
    "csv_filename = os.path.basename(gbif_path_broad)\n",
    "\n",
    "broad_gbif = \"broad-gbif.csv\"\n",
    "new_path2 = os.path.join(broad_dir, broad_gbif)\n",
    "\n",
    "os.rename(gbif_path_broad, new_path2)\n",
    "\n",
    "print(f\"Renamed {csv_filename} → {broad_gbif}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c336fab",
   "metadata": {},
   "source": [
    "## Step 5: Define Study Area: Ecoregions of North America and import GBIF data\n",
    "\n",
    "In this section:\n",
    "- Collect the directy for the ecoregion of North America and ensure it is plotting correctly\n",
    "- Load the collected GBIF data into the notebook as a dataframe\n",
    "- Change the data from a data frame (DF) to a geodatafram (GDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cf5efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Get url for ecoregions\n",
    "eco_url = (\"https://storage.googleapis.com/\"\n",
    "       \"teow2016/Ecoregions2017.zip\")\n",
    "\n",
    "### Make them machine readable\n",
    "eco_dir = os.path.join(data_dir, \"ecoregions\")\n",
    "\n",
    "### Make the ecoregions directory\n",
    "os.makedirs(eco_dir, exist_ok = True)\n",
    "\n",
    "### Join ecoregions shapefile path\n",
    "eco_path = os.path.join(eco_dir, \"ecoregions.shp\")\n",
    "\n",
    "### Download the data (once)\n",
    "if not os.path.exists(eco_path):\n",
    "    eco_gdf = gpd.read_file(eco_url)\n",
    "    eco_gdf.to_file(eco_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b038e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open up the ecoregions boundaries\n",
    "eco_gdf = (\n",
    "    gpd.read_file(eco_path)\n",
    "    [['OBJECTID', 'ECO_NAME', 'SHAPE_AREA', 'geometry' ]]\n",
    "   \n",
    ")\n",
    "    \n",
    "\n",
    "# Name the index so it will match the other data later on\n",
    "#eco_gdf.index.name = 'ecoregions'\n",
    "# Plot the ecoregions quickly to check download\n",
    "eco_gdf.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906809d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#View the data\n",
    "eco_gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c8fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that files were extracted into the correct directory\n",
    "print(\"Files in directory after extraction:\", os.listdir(data_dir))\n",
    "print(\"Ruby folder:\", os.listdir(ruby_dir))\n",
    "print(\"Broad folder:\", os.listdir(broad_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c957c8a1",
   "metadata": {},
   "source": [
    "## Step 6: Load GBIF dataframe and turn into geodataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a0119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GBIF dataframe\n",
    "gbif_ruby_df = pd.read_csv(\n",
    "    new_path1,\n",
    "    delimiter = '\\t',\n",
    "    index_col='gbifID',\n",
    "    usecols = ['gbifID', 'decimalLatitude', 'decimalLongitude', 'month'])\n",
    "\n",
    "### Check out data\n",
    "gbif_ruby_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617b5709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the GBIF dataframe\n",
    "\n",
    "\n",
    "gbif_broad_df = pd.read_csv(\n",
    "    new_path2,\n",
    "    delimiter = '\\t',\n",
    "    index_col='gbifID',\n",
    "    usecols = ['gbifID', 'decimalLatitude', 'decimalLongitude', 'month'])\n",
    "\n",
    "### Check out data\n",
    "gbif_broad_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8a732f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert GBIF data to GDF\n",
    "gbif_ruby_gdf = (\n",
    "    gpd.GeoDataFrame(\n",
    "        gbif_ruby_df, \n",
    "        geometry=gpd.points_from_xy(\n",
    "            gbif_ruby_df.decimalLongitude, \n",
    "            gbif_ruby_df.decimalLatitude), \n",
    "        crs=\"EPSG:4326\") #Using latitude and longitude in degrees\n",
    "    # Select the desired columns\n",
    "    [['month', 'geometry']]\n",
    ")\n",
    "\n",
    "# View the data\n",
    "gbif_ruby_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d974dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert GBIF data to GDF\n",
    "gbif_broad_gdf = (\n",
    "    gpd.GeoDataFrame(\n",
    "        gbif_broad_df, \n",
    "        geometry=gpd.points_from_xy(\n",
    "            gbif_broad_df.decimalLongitude, \n",
    "            gbif_broad_df.decimalLatitude), \n",
    "        crs=\"EPSG:4326\") #Using latitude and longitude in degrees\n",
    "    # Select the desired columns\n",
    "    [['month', 'geometry']]\n",
    ")\n",
    "\n",
    "# View the data\n",
    "gbif_broad_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027e8f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the data is a Geo Data Frame\n",
    "gbif_ruby_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d597001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the data is a Geo Data Frame\n",
    "gbif_broad_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf393f89",
   "metadata": {},
   "source": [
    "## Step 7: Consolidate dataframe data into ecoregion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d503c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out what CRS the data are in\n",
    "print(eco_gdf.crs)\n",
    "\n",
    "# Plot\n",
    "eco_gdf.plot(\n",
    "    color = \"lightblue\",\n",
    "    edgecolor = \"black\"\n",
    ")\n",
    "\n",
    "# Give it labels\n",
    "plt.xlabel(\"Longitude\")\n",
    "plt.ylabel(\"Latitude\")\n",
    "plt.title(\"Testing\")\n",
    "\n",
    "print(\"Ruby\" , gbif_ruby_gdf.crs)\n",
    "\n",
    "print(gbif_ruby_gdf)\n",
    "\n",
    "print(\"Broad tailed\" , gbif_broad_gdf.crs)\n",
    "\n",
    "print(gbif_broad_gdf)\n",
    "\n",
    "print(eco_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e83fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif_eco_ruby_gdf = (\n",
    "    eco_gdf\n",
    "    # Match the CRS of the GBIF data and the ecoregions\n",
    "    .to_crs(gbif_ruby_gdf.crs)\n",
    "    # Find ecoregion for each observation\n",
    "    .sjoin(\n",
    "        gbif_ruby_gdf,\n",
    "        how = 'inner', \n",
    "        \n",
    "        # only include ecoregions with gbif\n",
    "        predicate='contains') # Using points and polygons\n",
    "\n",
    "    # select columns we care about\n",
    "    [['OBJECTID', 'month']]\n",
    "    .rename(columns = {'OBJECTID': 'eco-region'})\n",
    ")\n",
    "gbif_eco_ruby_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a280d751",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif_eco_broad_gdf = (\n",
    "    eco_gdf\n",
    "    # Match the CRS of the GBIF data and the ecoregions\n",
    "    .to_crs(gbif_broad_gdf.crs)\n",
    "    # Find ecoregion for each observation\n",
    "    .sjoin(\n",
    "        gbif_broad_gdf,\n",
    "        how = 'inner', \n",
    "        \n",
    "        # only include ecoregions with gbif\n",
    "        predicate='contains') # Using points and polygons\n",
    "\n",
    "    # select columns we care about\n",
    "    [['OBJECTID', 'month']]\n",
    "    .rename(columns = {'OBJECTID': 'eco-region'})\n",
    ")\n",
    "gbif_eco_broad_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296b89e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif_eco_ruby_gdf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3101c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbif_eco_broad_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29415e3",
   "metadata": {},
   "source": [
    "## Step 8: Normalize hummingbird occurrences data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c81af1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence_ruby_df = (\n",
    "    gbif_eco_ruby_gdf\n",
    "\n",
    "    # Ecoregions by month\n",
    "    .groupby(['eco-region', 'month'])\n",
    "\n",
    "    # Count the number of occurrences\n",
    "    .agg(occurrences=('eco-region', 'count'))\n",
    ")\n",
    "\n",
    "# Get rid of rare observations \n",
    "occurrence_ruby_df = occurrence_ruby_df[occurrence_ruby_df.occurrences > 1] # Only include occurences wiht more than one recorded\n",
    "\n",
    "# Take the mean by ecoregion\n",
    "mean_occurrences_ruby_by_ecoregion = (\n",
    "    occurrence_ruby_df\n",
    "    .groupby('eco-region')\n",
    "    .mean()\n",
    ")\n",
    "mean_occurrences_ruby_by_ecoregion\n",
    "\n",
    "# Take the mean by month\n",
    "mean_occurrences_ruby_by_month = (\n",
    "    occurrence_ruby_df\n",
    "    .groupby('month')\n",
    "    .mean()\n",
    ")\n",
    "mean_occurrences_ruby_by_month\n",
    "\n",
    "### summarize occurrences\n",
    "occurrence_ruby_df = (\n",
    "    gbif_eco_ruby_gdf\n",
    "    # # Select only necessary columns\n",
    "    # [[]]\n",
    "    # For each ecoregion, for each month...\n",
    "    .groupby(['eco-region', 'month'])\n",
    "    # ...count the number of occurrences\n",
    "    .agg(occurrences=('eco-region', 'count'))\n",
    ")\n",
    "print(mean_occurrences_ruby_by_ecoregion)\n",
    "\n",
    "print(mean_occurrences_ruby_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4399f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence_broad_df = (\n",
    "    gbif_eco_broad_gdf\n",
    "\n",
    "    # Ecoregions by month\n",
    "    .groupby(['eco-region', 'month'])\n",
    "\n",
    "    # Count the number of occurrences\n",
    "    .agg(occurrences=('eco-region', 'count'))\n",
    ")\n",
    "\n",
    "# Get rid of rare observations \n",
    "occurrence_broad_df = occurrence_broad_df[occurrence_broad_df.occurrences > 1] # Only include occurences wiht more than one recorded\n",
    "\n",
    "# Take the mean by ecoregion\n",
    "mean_occurrences_broad_by_ecoregion = (\n",
    "    occurrence_broad_df\n",
    "    .groupby('eco-region')\n",
    "    .mean()\n",
    ")\n",
    "mean_occurrences_broad_by_ecoregion\n",
    "\n",
    "# Take the mean by month\n",
    "mean_occurrences_broad_by_month = (\n",
    "    occurrence_broad_df\n",
    "    .groupby('month')\n",
    "    .mean()\n",
    ")\n",
    "mean_occurrences_broad_by_month\n",
    "\n",
    "### summarize occurrences\n",
    "occurrence_broad_df = (\n",
    "    gbif_eco_broad_gdf\n",
    "    # # Select only necessary columns\n",
    "    # [[]]\n",
    "    # For each ecoregion, for each month...\n",
    "    .groupby(['eco-region', 'month'])\n",
    "    # ...count the number of occurrences\n",
    "    .agg(occurrences=('eco-region', 'count'))\n",
    ")\n",
    "print(mean_occurrences_broad_by_ecoregion)\n",
    "\n",
    "print(mean_occurrences_broad_by_month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfbdb5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by space and time for sampling effort\n",
    "occurrence_ruby_df['norm_occurrences'] = (\n",
    "    occurrence_ruby_df\n",
    "    / mean_occurrences_ruby_by_month # Divide by monthly occurrences\n",
    "    / mean_occurrences_ruby_by_ecoregion # Divide by ecoregion occurrences\n",
    ")\n",
    "occurrence_ruby_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc83f148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize by space and time for sampling effort\n",
    "occurrence_broad_df['norm_occurrences'] = (\n",
    "    occurrence_broad_df\n",
    "    / mean_occurrences_broad_by_month # Divide by monthly occurrences\n",
    "    / mean_occurrences_broad_by_ecoregion # Divide by ecoregion occurrences\n",
    ")\n",
    "occurrence_broad_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4415fbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the data\n",
    "\n",
    "# Histogram\n",
    "occurrence_ruby_df.norm_occurrences.plot.hist()\n",
    "\n",
    "# Scatterplot\n",
    "occurrence_ruby_df.reset_index().plot.scatter(\n",
    "    x = 'month',\n",
    "    y = 'norm_occurrences',\n",
    "    c = 'eco-region',\n",
    "    logy = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a4f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look at the data\n",
    "\n",
    "# Histogram\n",
    "occurrence_broad_df.norm_occurrences.plot.hist()\n",
    "\n",
    "# Scatterplot\n",
    "occurrence_broad_df.reset_index().plot.scatter(\n",
    "    x = 'month',\n",
    "    y = 'norm_occurrences',\n",
    "    c = 'eco-region',\n",
    "    logy = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ffa458",
   "metadata": {},
   "source": [
    "## Step 9: Make side by side visuals of occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4)) # 1 column and 2 rows\n",
    "\n",
    "# Plot each in their own axes\n",
    "occurrence_ruby_df.norm_occurrences.plot.hist(ax=axes[0], color =\"purple\").set_title(\"Ruby Occurrences in 2024\")\n",
    "\n",
    "occurrence_broad_df.norm_occurrences.plot.hist(ax=axes[1], color = \"green\").set_title(\"Broad-Tailed Occurrences in 2024\"), \n",
    "\n",
    "ymax = max(axes[0].get_ylim()[1], axes[1].get_ylim()[1])\n",
    "axes[0].set_ylim(0, ymax)\n",
    "axes[1].set_ylim(0, ymax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9916751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create side-by-side subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4)) # 1 column and 2 rows\n",
    "\n",
    "\n",
    "# Scatterplot\n",
    "occurrence_ruby_df.reset_index().plot.scatter(ax=axes[0],\n",
    "    x = 'month',\n",
    "    y = 'norm_occurrences',\n",
    "    c = 'eco-region',\n",
    "    logy = True\n",
    ").set_title(\"Ruby Occurrences in 2024\")\n",
    "# Scatterplot\n",
    "occurrence_broad_df.reset_index().plot.scatter(ax=axes[1],\n",
    "    x = 'month',\n",
    "    y = 'norm_occurrences',\n",
    "    c = 'eco-region').set_title(\"Broad-Tailed Occurrences in 2024\")\n",
    "\n",
    "ymax = max(axes[0].get_ylim()[1], axes[1].get_ylim()[1])\n",
    "axes[0].set_ylim(0, ymax)\n",
    "axes[1].set_ylim(0, ymax)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd634d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplify the geometry to speed up processing\n",
    "eco_gdf.geometry = eco_gdf.simplify(0.1, preserve_topology=False)\n",
    "\n",
    "\n",
    "# Change the CRS to Mercator for mapping\n",
    "eco_gdf = eco_gdf.to_crs(ccrs.Mercator())\n",
    "\n",
    "# Check that the plot runs in a reasonable amount of time\n",
    "eco_gdf.hvplot(geo=True, crs=ccrs.Mercator())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7835f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rename eco_gdf to match occurrence_df\n",
    "eco_gdf = eco_gdf.rename(columns = {'OBJECTID' : 'eco-region'})\n",
    "\n",
    "## Merge ecoregio index\n",
    "eco_gdf = eco_gdf.set_index('eco-region')\n",
    "eco_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52bff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Join the occurrences with the plotting GeoDataFrame\n",
    "occurrence_ruby_gdf = eco_gdf.join(occurrence_ruby_df)\n",
    "\n",
    "# Get the plot bounds so they don't change with the slider\n",
    "xmin, ymin, xmax, ymax = occurrence_ruby_gdf.total_bounds\n",
    "\n",
    "# Calendar Name slider\n",
    "month_widget = pn.widgets.DiscreteSlider(\n",
    "    options={\n",
    "        calendar.month_name[month_num]: month_num\n",
    "        for month_num in range(1, 12)\n",
    "        }\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f34d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrence_ruby_df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742408aa",
   "metadata": {},
   "source": [
    "## Step 10: Make some maps of the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc14bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot occurrence by ecoregion and month\n",
    "migration_ruby_plot = (\n",
    "    occurrence_ruby_gdf\n",
    "    .hvplot(\n",
    "      \n",
    "        groupby='month',\n",
    "        # Use background tiles\n",
    "        geo=True, crs=ccrs.Mercator(), tiles='CartoLight',\n",
    "        title=\"Ruby Throated Hummingbird Migration in 2024\",\n",
    "        xlim=(xmin, xmax), ylim=(ymin, ymax),\n",
    "        frame_height=600,\n",
    "        widgets={'month': month_widget},\n",
    "        widget_location='bottom' # location of slider\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save the plot\n",
    "migration_ruby_plot.save('migration-ruby-final.html', embed=True)\n",
    "\n",
    "migration_ruby_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2c085a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the occurrences with the plotting GeoDataFrame\n",
    "occurrence_broad_gdf = eco_gdf.join(occurrence_broad_df)\n",
    "\n",
    "# Get the plot bounds so they don't change with the slider\n",
    "xmin, ymin, xmax, ymax = occurrence_broad_gdf.total_bounds\n",
    "\n",
    "# Calendar Name slider\n",
    "month_widget = pn.widgets.DiscreteSlider(\n",
    "    options={\n",
    "        calendar.month_name[month_num]: month_num\n",
    "        for month_num in range(1, 12)\n",
    "        }\n",
    ")\n",
    "\n",
    "# Plot occurrence by ecoregion and month\n",
    "migration_broad_plot = (\n",
    "    occurrence_broad_gdf\n",
    "    .hvplot(\n",
    "        groupby='month',\n",
    "        # Use background tiles\n",
    "        geo=True, crs=ccrs.Mercator(), tiles='CartoLight',\n",
    "        title=\"Broad-Tailed Hummingbird Migration in 2024\",\n",
    "        xlim=(xmin, xmax), ylim=(ymin, ymax),\n",
    "        frame_height=600,\n",
    "        widgets={'month': month_widget},\n",
    "        widget_location='bottom', # location of slider,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Save the plot\n",
    "migration_broad_plot.save('migration-broad-final.html', embed=True)\n",
    "\n",
    "migration_broad_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2e7a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot occurrence by ecoregion and month\n",
    "\n",
    "\n",
    "migration_ruby_broad_plot = (\n",
    "    \n",
    "    occurrence_ruby_gdf\n",
    "    .hvplot(\n",
    "        groupby='month',\n",
    "        # Use background tiles\n",
    "        geo=True, crs=ccrs.Mercator(), tiles='CartoLight',\n",
    "        title=\"Broad-Tailed Hummingbird Migration in 2024\",\n",
    "        xlim=(xmin, xmax), ylim=(ymin, ymax),\n",
    "        frame_height=600,\n",
    "        widgets={'month': month_widget},\n",
    "        widget_location='bottom', # location of slider,\n",
    "    )\n",
    "\n",
    "    \n",
    ")\n",
    "\n",
    "# Save the plot\n",
    "#migration_ruby_broad_plot.save('migration-ruby-broad-final.html', embed=True)\n",
    "\n",
    "migration_ruby_broad_plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9af44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruby_hv = migration_ruby_plot[0].object\n",
    "broad_hv = migration_broad_plot[0].object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e8a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = ruby_hv * broad_hv\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24e0aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "hv.extension('bokeh')\n",
    "\n",
    "month_dim = ruby_hv.kdims[0]  # usually 'month'\n",
    "\n",
    "combined_dm = hv.DynamicMap(\n",
    "    lambda month: (ruby_hv[month]*\n",
    "                   broad_hv[month]\n",
    "                  ).opts(\n",
    "                      title='Ruby vs Broad-Tailed Occurrences in 2024',\n",
    "                      width=800,\n",
    "                      height=600\n",
    "                  ),\n",
    "    kdims=[month_dim]\n",
    ")\n",
    "\n",
    "combined_dm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab67bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "hv.extension('bokeh')\n",
    "\n",
    "def combined_layer(month):\n",
    "    ruby_points = get_points_layer(ruby_hv, month).to_dataframe()\n",
    "    broad_points = get_points_layer(broad_hv, month).to_dataframe()\n",
    "    \n",
    "    # Find overlapping geometries\n",
    "    overlap = pd.merge(ruby_points, broad_points, on='geometry', how='inner')\n",
    "    ruby_only = ruby_points[~ruby_points.geometry.isin(overlap.geometry)]\n",
    "    broad_only = broad_points[~broad_points.geometry.isin(overlap.geometry)]\n",
    "    \n",
    "    # Create Points layers\n",
    "    ruby_layer  = ruby_only.hvplot.points(geo=True, color='purple', alpha=0.6, size=8)\n",
    "    broad_layer = broad_only.hvplot.points(geo=True, color='green', alpha=0.6, size=8)\n",
    "    overlap_layer = overlap.hvplot.points(geo=True, color='red', alpha=0.8, size=8)\n",
    "    \n",
    "    return ruby_layer * broad_layer * overlap_layer\n",
    "\n",
    "combined_dm = hv.DynamicMap(\n",
    "    combined_layer,\n",
    "    kdims=ruby_hv.kdims\n",
    ")\n",
    "\n",
    "combined_dm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671b4c5",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
